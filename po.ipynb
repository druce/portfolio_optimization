{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [README.md](https://github.com/druce/portfolio_optimization/blob/master/README.md) for discussion, environment setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time \n",
    "import requests\n",
    "import dotenv\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import xlrd\n",
    "\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster, leaves_list\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import openbb\n",
    "from openbb import obb\n",
    "from openbb_core.app.model.obbject import OBBject\n",
    "\n",
    "# https://www.cvxpy.org/install/index.html\n",
    "import cvxpy as cp\n",
    "\n",
    "# https://riskfolio-lib.readthedocs.io/en/latest/\n",
    "import riskfolio as rp\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(2347)\n",
    "\n",
    "print(\"%-20s %s\" % ('python', \".\".join(map(str, sys.version_info[:3]))))\n",
    "print(\"%-20s %s\" % (\"numpy\", np.__version__))\n",
    "print(\"%-20s %s\" % (\"scipy\", scipy.__version__))\n",
    "\n",
    "print(\"%-20s %s\" % (\"pandas\", pd.__version__))\n",
    "print(\"%-20s %s\" % (\"pandas-datareader\", pdr.__version__))\n",
    "# print(\"%-20s %s\" % (\"xlrd\", xlrd.__version__))\n",
    "print(\"%-20s %s\" % (\"seaborn\", sns.__version__))\n",
    "print(\"%-20s %s\" % (\"matplotlib\", matplotlib.__version__))\n",
    "print(\"%-20s %s\" % (\"cvxpy\", cp.__version__))\n",
    "print(\"%-20s %s\" % (\"openbb\", obb.system.version))\n",
    "\n",
    "print(\"%-20s %s\" % (\"riskfolio\", rp.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spreadsheet from Damodaran website into pandas dataframe\n",
    "\n",
    "# if below gives cert error\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "data_xls = 'https://www.stern.nyu.edu/~adamodar/pc/datasets/histretSP.xls'\n",
    "data_sheet = \"Returns by year\"\n",
    "# these will change as rows get added on Damodaran website\n",
    "skiprows = range(19)\n",
    "skipfooter = 13\n",
    "download_df = pd.read_excel(data_xls, \n",
    "                         sheet_name=data_sheet, \n",
    "                         skiprows=skiprows,\n",
    "                         skipfooter=skipfooter)\n",
    "download_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index to year as int\n",
    "download_df[\"Year\"] = download_df[\"Year\"].astype(int)\n",
    "download_df.set_index(download_df[\"Year\"], inplace=True)\n",
    "download_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download GDP for correlation matrix\n",
    "series = ['GDPCA']\n",
    "\n",
    "gdp_download = pdr.data.DataReader(series, \n",
    "                                   'fred', \n",
    "                                   start='1926-12-31')\n",
    "gdp_download.reset_index(inplace=True)\n",
    "gdp_download.set_index(pd.DatetimeIndex(gdp_download['DATE']).year, inplace=True)\n",
    "gdp_download['GDP'] = gdp_download['GDPCA'].pct_change()\n",
    "# https://fortunly.com/statistics/us-gdp-by-year-guide/#gref\n",
    "gdp_download.loc[1928, 'GDP'] = 0.0110\n",
    "gdp_download.loc[1929, 'GDP'] = 0.0652\n",
    "gdp_download.sort_index(inplace=True)\n",
    "gdp_download.to_csv('gdp_fred.csv')\n",
    "\n",
    "gdp_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df = download_df.copy()\n",
    "real_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use caution to grab real return columns, not nominal, column names are similar\n",
    "# check values vs. sheet\n",
    "real_data_df = download_df.copy()\n",
    "real_data_df = real_data_df.drop(columns=[\"Real Estate\"])\n",
    "real_data_df = real_data_df.rename(\n",
    "    columns={\n",
    "        \"Real Estate\": \"Real Estate (nominal)\",\n",
    "        'Inflation Rate': 'CPI',\n",
    "        'S&P 500 (includes dividends)2': 'S&P',\n",
    "        \"US Small cap (bottom decile)22\": \"Small Caps\",\n",
    "        '!0-year T.Bonds': 'T-Notes',\n",
    "        '3-month T. Bill (Real)': 'T-Bills',\n",
    "        'Baa Corp Bonds': 'Baa Corps',\n",
    "        'Real Estate3': 'Real Estate',\n",
    "    })\n",
    "\n",
    "real_data_df[\"GDP\"] = gdp_download['GDP']\n",
    "# filter and reorder\n",
    "real_data_df = real_data_df[[\n",
    "    'GDP',\n",
    "    'CPI',\n",
    "    'S&P',\n",
    "    'Small Caps',\n",
    "    'T-Bills',\n",
    "    'T-Notes',\n",
    "    'Baa Corps',\n",
    "    'Real Estate',\n",
    "    'Gold',\n",
    "]]\n",
    "real_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumreturns = (1 + real_data_df.copy()).cumprod()\n",
    "(cumreturns.iloc[-1]-1)**(1/len(cumreturns))-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # display all rows without truncation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in real_data_df.columns:\n",
    "    real_data_df[col] = real_data_df[col].astype(float)\n",
    "\n",
    "# compute correlation matrix\n",
    "my_cmap = sns.diverging_palette(10, 220, sep=80, n=50)\n",
    "sns.heatmap(real_data_df.corr(), annot=True, fmt=\".02f\", cmap=my_cmap);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop CPI, GDP which are not assets\n",
    "try:\n",
    "    real_data_df.drop(labels=['CPI', 'GDP'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "df = real_data_df.copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.line();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix\n",
    "my_cmap = sns.diverging_palette(10, 220, sep=80, n=50)\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".02f\", cmap=my_cmap);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot historical cumulative growth\n",
    "df2 = df.copy()\n",
    "for col in df2.columns:\n",
    "    df2[col]+= 1\n",
    "    df2[col] = df2[col].cumprod()\n",
    "    \n",
    "df2.plot.line();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot historical cumulative growth since 1970\n",
    "df2 = df.copy().loc[1970:]\n",
    "for col in df2.columns:\n",
    "    df2[col]+= 1\n",
    "    df2[col] = df2[col].cumprod()\n",
    "    \n",
    "df2.plot.line();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(df.columns)\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-only optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1928 - present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arithmetic means\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geometric mean\n",
    "cumreturns = (1 + df.copy()).cumprod()\n",
    "(cumreturns.iloc[-1]-1)**(1/len(cumreturns))-1\n",
    "# difference due to volatility and compounding and maybe divergences from IID log normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute covariance matrix\n",
    "Sigma = np.cov(df.transpose())\n",
    "# number of assets\n",
    "\n",
    "n = Sigma.shape[0]\n",
    "# average returns\n",
    "mu = df.mean().values\n",
    "# asset STDs\n",
    "asset_vols = np.sqrt(Sigma.diagonal())\n",
    "# variable to optimize over - portfolio weights\n",
    "w = cp.Variable(n)\n",
    "\n",
    "# objectives to optimize\n",
    "# portfolio return\n",
    "ret = mu.T @ w \n",
    "# volatility\n",
    "vol = cp.quad_form(w, Sigma)\n",
    "\n",
    "z = pd.DataFrame([mu, asset_vols], columns=labels)\n",
    "z['rows'] = ['real return', 'vol']\n",
    "z.set_index('rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve max return portfolio (corner solution)\n",
    "# should be 100% highest return asset\n",
    "prob = cp.Problem(cp.Maximize(ret),      # maximize return\n",
    "                  [cp.sum(w) == 1,       # weights sum to 1\n",
    "                   w >= 0]               # each w > 0\n",
    "                 )\n",
    "prob.solve()\n",
    "wts = [float('%0.4f' % v) for v in w.value]\n",
    "maxretvol = vol.value\n",
    "maxret = ret.value\n",
    "print(\"Max return portfolio weights\")\n",
    "pd.DataFrame([wts], columns=labels)\n",
    "# all stocks which is highest return asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve min vol portfolio (other corner solution)\n",
    "# should be mostly T-bills but there is variance in t-bills so it diversifies\n",
    "prob = cp.Problem(cp.Minimize(vol),\n",
    "                  [cp.sum(w) == 1,     # weights sum to 1\n",
    "                   w >= 0],            # each weight >= 0\n",
    "                 )\n",
    "prob.solve()\n",
    "# round to not get x.xxxxE-22\n",
    "wts = [float('%0.6f' % v) for v in w.value]\n",
    "\n",
    "minvol = vol.value\n",
    "minvolret = ret.value\n",
    "print(\"Min vol portfolio weights\")\n",
    "pd.DataFrame([wts], columns=labels)\n",
    "# mostly t-bills and real estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# solve points in between\n",
    "# for a series of points between min and max vol, maximize return subject to volatility constraints \n",
    "\n",
    "# specify a Parameter variable instead of creating new Problem at each iteration\n",
    "# this allows the solver to reuse previous work\n",
    "vol_limit = cp.Parameter(nonneg=True)\n",
    "\n",
    "prob = cp.Problem(cp.Maximize(ret),\n",
    "                  [cp.sum(w) == 1, \n",
    "                   w >= 0,\n",
    "                   vol <= vol_limit\n",
    "                  ]\n",
    "                 )\n",
    "\n",
    "# define function so we can solve many in parallel\n",
    "def solve_vl(vl_val):\n",
    "    vol_limit.value = vl_val\n",
    "    result = prob.solve()\n",
    "    return (ret.value, np.sqrt(vol.value), w.value)\n",
    "\n",
    "# number of points on the frontier\n",
    "NPOINTS = 200\n",
    "vl_vals = np.linspace(np.sqrt(minvol), np.sqrt(maxretvol), NPOINTS)\n",
    "vl_vals = np.square(vl_vals)\n",
    "# vol constraint is in variance space, take square root of minvol and maxvol, linspace, square values)\n",
    "\n",
    "# iterate in-process\n",
    "results_dict = {}\n",
    "for vl_val in vl_vals:\n",
    "    # print(datetime.strftime(datetime.now(), \"%H:%M:%S\"), vl_val)\n",
    "    results_dict[vl_val] = solve_vl(vl_val)\n",
    "    \n",
    "# parallel implementation\n",
    "# NPROCESSES = 8\n",
    "# pool = Pool(processes = NPROCESSES)\n",
    "# result_values = pool.map(solve_vl, vl_vals)\n",
    "# results_dict = dict(zip(vl_vals, result_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_df = pd.DataFrame(enumerate(results_dict.keys()))\n",
    "ret_df.columns=['i', 'vol']\n",
    "ret_df['return'] = [results_dict[v][0] for v in ret_df['vol']]\n",
    "ret_df['std'] = [results_dict[v][1] for v in ret_df['vol']]\n",
    "for i, colname in enumerate(labels):\n",
    "    ret_df[colname]=[results_dict[v][2][i] for v in ret_df['vol']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot efficient frontier\n",
    "def plot_efrontier(ret_df, df,\n",
    "                   xlabel=\"Standard Deviation of Real Returns\",\n",
    "                   ylabel=\"Real Return\",\n",
    "                   title=None):\n",
    "\n",
    "    Sigma = np.cov(df.transpose())\n",
    "    n = Sigma.shape[0]\n",
    "    mu = df.mean().values\n",
    "    asset_vols = np.sqrt(Sigma.diagonal())\n",
    "\n",
    "    risk_free_rate = 0  # availability of any risk-free real rate in this context is debatable \n",
    "    ret_df[\"Sharpe\"] = (ret_df[\"return\"] - risk_free_rate) / ret_df[\"std\"]\n",
    "    \n",
    "    max_sharpe_index = ret_df[\"Sharpe\"].argmax()  \n",
    "#     print(max_sharpe_index)\n",
    "    max_sharpe_return = ret_df.iloc[max_sharpe_index][\"return\"]\n",
    "#     print(max_sharpe_return)\n",
    "    max_sharpe_std = ret_df.iloc[max_sharpe_index][\"std\"]\n",
    "#     print(max_sharpe_std)\n",
    "    max_sharpe_ratio = ret_df.iloc[max_sharpe_index][\"Sharpe\"]\n",
    "    \n",
    "    asset_names = [t for t in ['TIPS', 'T-Bills', 'Real Estate', 'T-Notes', 'Baa Corps', 'Gold', 'S&P', 'Small Caps', 'shorts'] if t in ret_df.columns]\n",
    "    \n",
    "    mean_wts = ret_df[asset_names].mean() # average weights over all efficient portolios\n",
    "    temp_ret_df = df[asset_names]         # historical returns\n",
    "    avg_ret = temp_ret_df @ mean_wts.values\n",
    "    avg_ret_mean = avg_ret.mean()\n",
    "    avg_ret_std = avg_ret.std()\n",
    "    \n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "\n",
    "    # plot the data\n",
    "    plt.plot(ret_df['std'], ret_df['return'])\n",
    "    # Force both axes to start at 0\n",
    "    plt.xlim(left=0, right=max(asset_vols))\n",
    "    plt.ylim(bottom=min(0, min(mu)))\n",
    "    \n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plot_title = \"Risk vs. Real Return,  %d-%d\" % (df.index[0], df.index[-1]) if title is None else title\n",
    "    plt.title(plot_title)\n",
    "\n",
    "    # plot the markers\n",
    "    plt.scatter(asset_vols, mu)\n",
    "    xoffset = 0.0025\n",
    "    yoffset = 0.0015\n",
    "    labels = df.columns\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.annotate(label, xy=(asset_vols[i]+xoffset, mu[i]+yoffset), xycoords='data',\n",
    "                     horizontalalignment='left', verticalalignment='top',\n",
    "                    )\n",
    "    plt.scatter([max_sharpe_std], [max_sharpe_return])\n",
    "    plt.annotate(\"Max Sharpe\", xy=(max_sharpe_std+xoffset, max_sharpe_return+yoffset), xycoords='data',\n",
    "                 horizontalalignment='left', verticalalignment='top',\n",
    "                )\n",
    "    plt.scatter([avg_ret_std], [avg_ret_mean])\n",
    "    plt.annotate(\"EF Avg Wts\", xy=(avg_ret_std+xoffset, avg_ret_mean+yoffset), xycoords='data',\n",
    "                 horizontalalignment='left', verticalalignment='top',\n",
    "                )\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    print(\"Max Sharpe Portfolio:\")\n",
    "    print(f\"Real Return:  {100*max_sharpe_return:3.2f}%\")\n",
    "    print(f\"SD:           {100*max_sharpe_std:3.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {max_sharpe_ratio:3.3f}\")\n",
    "\n",
    "    for col in asset_names:\n",
    "        print(f\"{col}: {100*ret_df.iloc[max_sharpe_index][col]:3.1f}%\")\n",
    "  \n",
    "    print()\n",
    "    print(\"Average over efficient frontier:\")\n",
    "    print(f\"Real Return:  {100*avg_ret_mean:3.2f}%\")\n",
    "    print(f\"SD:           {100*avg_ret_std:3.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {avg_ret_mean/avg_ret_std:3.3f}\")\n",
    "    for col in asset_names:\n",
    "        print(f\"{col}: {100*mean_wts[col]:3.1f}%\")\n",
    "            \n",
    "    return max_sharpe_return, max_sharpe_std, avg_ret_mean, avg_ret_std\n",
    "        \n",
    "max_sharpe_return, max_sharpe_std, avg_ret_mean, avg_ret_std = plot_efrontier(ret_df, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked area chart of weights vs. returns\n",
    "# for given vol constraint and corresponding real return, show portfolio weights\n",
    "def transition_map(ret_df, labels, startyear, endyear, max_sharpe_return=None, avg_ret_mean=None, ylim=1):\n",
    "    \n",
    "    x = ret_df['return']\n",
    "    # absolute values so shorts don't create chaos\n",
    "    y_list = [abs(ret_df[l]) for l in labels]\n",
    "    pal = ['red', 'lightgreen', 'darkgreen', 'navy', 'cyan', 'violet', 'gold', ]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 4.5))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "  \n",
    "    ax1.stackplot(x, y_list, labels=labels, colors=pal)\n",
    "    ax1.set_xlim((ret_df['return'].iloc[0], ret_df['return'].iloc[-1]))\n",
    "    ax1.set_ylim((0, ylim))\n",
    "    ax1.set_xlabel('Portfolio Vol')\n",
    "    ax1.set_xlabel(\"Portfolio Real Return\")\n",
    "    ax1.set_ylabel(\"Portfolio Weight\")\n",
    "    ax1.legend(loc='lower right')\n",
    "#     return/std relationship is not linear, can't have both axes\n",
    "#     ax2 = ax1.twiny()\n",
    "#     ax2.set_xlim((ret_df['std'].iloc[0], ret_df['std'].iloc[-1]))\n",
    "#     ax2.set_xlabel('Portfolio Vol')\n",
    "    \n",
    "    if max_sharpe_return is not None:\n",
    "        ax1.axvline(max_sharpe_return, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "# don't draw line for avg_ret_mean, doesn't correspond to a portfolio in the transition map\n",
    "#     if avg_ret_mean is not None:\n",
    "#         ax1.axvline(avg_ret_mean, color='black', linestyle='--', linewidth=1)\n",
    "        \n",
    "    plt.title(\"Optimal Portfolio Transition Map, %d-%d\" % (startyear, endyear), y=1.16);\n",
    "\n",
    "transition_map(ret_df, labels=df.columns, startyear=df.index[0], endyear=df.index[-1], max_sharpe_return=max_sharpe_return, avg_ret_mean=avg_ret_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a risk-free asset\n",
    "- The efficient frontier above does not include a risk-free asset, when we inflation-adjust t-bill returns we get volatility and fluctuation in returns including periods of negative real returns.\n",
    "- However TIPS are available which offer a guaranteed real pre-tax return. They are issued at a real rate, the principal gets adjusted for inflation, and if there is deflation you can't get back less than par. So when you buy TIPS you are guaranteed a positive real pre-tax return\n",
    "- TIPS offer an inflation hedge and a safe real return, so they might dominate gold. There isn't a great theoretical argument gold should increase in value faster than inflation in the long run (gold bugs might disagree but in a fiat world, that's my story and I'm sticking to it). I could see reasonable arguments why gold should maintain its real value if supply is fixed, and there should be demand for gold when there is inflation and people lose faith in monetary authorities because it is currency-like and supply is relatively fixed, so gold offers an inflation hedge. \n",
    "- TIPS total returns are only available for approximately the last 25 years. You can model the TIPS yield as the yield on similar nominal Treasuries less inflation expectations. Hypothetically, there might be a sound way to model historical inflation expectations using recent inflation trends, gold, steepness of yield curve etc. And from there, model what TIPS total returns would theoretically have been based on Treasury total returns and changes in inflation expectations, but that is a challenge. We could also say that the best inflation hedge was gold up to 2000 and TIPS thereafter and use VIPSX OR TIP, but that is a kinky Franken-asset.\n",
    "- We could also say that given the existence of TIPS, a risk-free 0 real yield asset is available. Worst case TIPS return is 0, if auction rate is 0. Or you could buy TIPS and donate any return over 0, and you are guaranteed return of principal plus inflation. You could argue that it wasn't available and if it had been then it would have modified other returns. If my aunt had wheels she'd be a bicycle.\n",
    "- Lets posit that we are justified in adding a risk-free TIPS asset, with a constant zero return.\n",
    "- In the real world you would get a positive real return on TIPS with some fluctuations, real TIPS should dominate the risk-free asset. So this model might underweight TIPS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = real_data_df.loc[1928:].copy()\n",
    "df[\"TIPS\"] = 0\n",
    "# reorder  for chart\n",
    "df = df[[ 'S&P', 'Small Caps', 'T-Notes', 'Baa Corps', 'TIPS', 'Real Estate', 'Gold', 'T-Bills' ]]\n",
    "labels = df.columns\n",
    "df.plot.line();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute covariance matrix\n",
    "Sigma = np.cov(df.transpose())\n",
    "\n",
    "# number of assets\n",
    "n = Sigma.shape[0]\n",
    "# average returns\n",
    "mu = df.mean().values\n",
    "# asset STDs\n",
    "asset_vols = np.sqrt(Sigma.diagonal())\n",
    "# variable to optimize over - portfolio weights\n",
    "w = cp.Variable(n)\n",
    "\n",
    "# objectives to optimize\n",
    "# portfolio return\n",
    "ret = mu.T @ w \n",
    "\n",
    "# volatility\n",
    "vol = cp.quad_form(w, Sigma)\n",
    "\n",
    "z = pd.DataFrame([mu, asset_vols], columns=labels)\n",
    "z['rows'] = ['real return', 'vol']\n",
    "z.set_index('rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve max return portfolio (corner solution)\n",
    "prob = cp.Problem(cp.Maximize(ret), \n",
    "                  [cp.sum(w) == 1, \n",
    "                   w >= 0]\n",
    "                 )\n",
    "prob.solve()\n",
    "wts = [float('%0.4f' % v) for v in w.value]\n",
    "maxretvol = vol.value\n",
    "maxret = ret.value\n",
    "print(\"Max return portfolio weights\")\n",
    "pd.DataFrame([wts], columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve min vol portfolio (other corner solution)\n",
    "prob = cp.Problem(cp.Minimize(vol),\n",
    "                  [cp.sum(w) == 1, \n",
    "                   w >= 0]\n",
    "                 )\n",
    "prob.solve()\n",
    "wts = [float('%0.4f' % v) for v in w.value]\n",
    "\n",
    "minvol = vol.value\n",
    "minvolret = ret.value\n",
    "print(\"Min vol portfolio weights\")\n",
    "pd.DataFrame([wts], columns=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# solve points in between\n",
    "# maximize return subject to volatility constraints between minimum volatility and max return volatility\n",
    "\n",
    "# specify a Parameter variable instead of creating new Problem at each iteration\n",
    "# this allows the solver to reuse previous work\n",
    "vol_limit = cp.Parameter(nonneg=True)\n",
    "\n",
    "prob = cp.Problem(cp.Maximize(ret),\n",
    "                  [cp.sum(w) == 1, \n",
    "                   w >= 0,\n",
    "                   vol <= vol_limit\n",
    "                  ]\n",
    "                 )\n",
    "\n",
    "# define function so we can solve many in parallel\n",
    "def solve_vl(vl_val):\n",
    "    vol_limit.value = vl_val\n",
    "    result = prob.solve()\n",
    "    return (ret.value, np.sqrt(vol.value), w.value)\n",
    "\n",
    "# number of points on the frontier\n",
    "NPOINTS = 200\n",
    "vl_vals = np.linspace(np.sqrt(minvol), np.sqrt(maxretvol), NPOINTS)\n",
    "vl_vals = np.square(vl_vals)\n",
    "# vol constraint is in variance space, take square root of minvol and maxvol, linspace, square values)\n",
    "\n",
    "# iterate in-process\n",
    "results_dict = {}\n",
    "for vl_val in vl_vals:\n",
    "    # print(datetime.strftime(datetime.now(), \"%H:%M:%S\"), vl_val)\n",
    "    results_dict[vl_val] = solve_vl(vl_val)\n",
    "    \n",
    "# parallel implementation\n",
    "# NPROCESSES = 8\n",
    "# pool = Pool(processes = NPROCESSES)\n",
    "# result_values = pool.map(solve_vl, vl_vals)\n",
    "# results_dict = dict(zip(vl_vals, result_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret_df = pd.DataFrame(enumerate(results_dict.keys()))\n",
    "ret_df.columns=['i', 'vol']\n",
    "ret_df['return'] = [results_dict[v][0] for v in ret_df['vol']]\n",
    "ret_df['std'] = [results_dict[v][1] for v in ret_df['vol']]\n",
    "for i, colname in enumerate(labels):\n",
    "    ret_df[colname]=[results_dict[v][2][i] for v in ret_df['vol']]\n",
    "# ret_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sharpe_return, max_sharpe_std, avg_ret_mean, avg_ret_std = plot_efrontier(ret_df, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_map(ret_df, labels=df.columns, startyear=df.index[0], endyear=df.index[-1], max_sharpe_return=max_sharpe_return, avg_ret_mean=avg_ret_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midwit regularization - take the mean of all optimal portfolios at any level of risk\n",
    "regularized = ret_df[['S&P', 'Small Caps', 'T-Notes',\n",
    "       'Baa Corps', 'TIPS', 'Real Estate', 'Gold', 'T-Bills']].mean()\n",
    "with pd.option_context('display.float_format', '{:.6f}'.format):\n",
    "    display(regularized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_map(ret_df, labels=df.columns, startyear=df.index[0], endyear=df.index[-1], max_sharpe_return=max_sharpe_return, avg_ret_mean=avg_ret_mean, ylim=1.0)\n",
    "# these are absolute values for gross exposure , not net exposure. \n",
    "# left looks weird because < 1.5 gross exposure but also additional Treasury shorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_optimization",
   "language": "python",
   "name": "py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
